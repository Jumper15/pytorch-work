{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9L71pCXmLLL0aiSngJyk6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jumper15/pytorch-work/blob/main/SLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0s97RRx7bwN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2z2TyYQ0ksw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.functional as F\n",
        "\n",
        "# string = open(\"names.txt\", \"r\").read(100)\n",
        "string = \"\"\"\n",
        "emma\n",
        "olivia\n",
        "ava\n",
        "isabella\n",
        "sophia\n",
        "charlotte\n",
        "mia\n",
        "amelia\n",
        "harper\n",
        "evelyn\n",
        "abigail\n",
        "emily\n",
        "elizabeth\n",
        "mila\n",
        "ella\n",
        "avery\n",
        "sofia\n",
        "camila\n",
        "aria\n",
        "scarlett\n",
        "victoria\n",
        "madison\n",
        "luna\n",
        "grace\n",
        "chloe\n",
        "penelope\n",
        "layla\n",
        "riley\n",
        "zoey\n",
        "nora\n",
        "lily\n",
        "eleanor\n",
        "hannah\n",
        "lillian\n",
        "addison\n",
        "aubrey\n",
        "ellie\n",
        "stella\n",
        "natalie\n",
        "zoe\n",
        "leah\n",
        "hazel\n",
        "violet\n",
        "aurora\n",
        "savannah\n",
        "audrey\n",
        "brooklyn\n",
        "bella\n",
        "claire\n",
        "skylar\n",
        "lucy\n",
        "paisley\n",
        "everly\n",
        "anna\n",
        "caroline\n",
        "nova\n",
        "genesis\n",
        "emilia\n",
        "kennedy\n",
        "samantha\n",
        "maya\n",
        "willow\n",
        "kinsley\n",
        "naomi\n",
        "aaliyah\n",
        "elena\n",
        "sarah\n",
        "ariana\n",
        "allison\n",
        "gabriella\n",
        "alice\n",
        "madelyn\n",
        "cora\n",
        "ruby\n",
        "eva\n",
        "serenity\n",
        "autumn\n",
        "adeline\n",
        "hailey\n",
        "gianna\n",
        "valentina\n",
        "isla\n",
        "eliana\n",
        "quinn\n",
        "nevaeh\n",
        "ivy\n",
        "sadie\n",
        "piper\n",
        "lydia\n",
        "alexa\n",
        "josephine\n",
        "emery\n",
        "julia\n",
        "delilah\n",
        "arianna\n",
        "vivian\n",
        "kaylee\n",
        "sophie\n",
        "brielle\n",
        "madeline\n",
        "peyton\n",
        "rylee\n",
        "clara\n",
        "hadley\n",
        "melanie\n",
        "mackenzie\n",
        "reagan\n",
        "adalynn\n",
        "liliana\n",
        "aubree\n",
        "jade\n",
        "katherine\n",
        "isabelle\n",
        "natalia\n",
        "raelynn\n",
        "maria\n",
        "athena\n",
        "ximena\n",
        "arya\n",
        "leilani\n",
        "taylor\n",
        "faith\n",
        "rose\n",
        "kylie\n",
        "alexandra\n",
        "mary\n",
        "margaret\n",
        "lyla\n",
        "ashley\n",
        "amaya\n",
        "eliza\n",
        "brianna\n",
        "bailey\n",
        "andrea\n",
        "khloe\n",
        "jasmine\n",
        "melody\n",
        "iris\n",
        "isabel\n",
        "norah\n",
        "annabelle\n",
        "valeria\n",
        "emerson\n",
        "adalyn\n",
        "ryleigh\n",
        "eden\n",
        "emersyn\n",
        "anastasia\n",
        "kayla\n",
        "alyssa\n",
        "juliana\n",
        "charlie\n",
        "esther\n",
        "ariel\n",
        "cecilia\n",
        "valerie\n",
        "alina\n",
        "molly\n",
        "reese\n",
        "aliyah\n",
        "lilly\n",
        "parker\n",
        "finley\n",
        "morgan\n",
        "sydney\n",
        "jordyn\n",
        "eloise\n",
        "trinity\n",
        "daisy\n",
        "kimberly\n",
        "lauren\n",
        "genevieve\n",
        "sara\n",
        "arabella\n",
        "harmony\n",
        "elise\n",
        "remi\n",
        "teagan\n",
        "alexis\n",
        "london\n",
        "sloane\n",
        "laila\n",
        "lucia\n",
        "diana\n",
        "juliette\n",
        "sienna\n",
        "elliana\n",
        "londyn\n",
        "ayla\n",
        "callie\n",
        "gracie\n",
        "josie\n",
        "amara\n",
        "jocelyn\n",
        "daniela\n",
        "everleigh\n",
        "mya\n",
        "rachel\n",
        "summer\n",
        "alana\n",
        "brooke\n",
        "alaina\n",
        "mckenzie\n",
        "catherine\n",
        "amy\n",
        "presley\n",
        "journee\n",
        "rosalie\n",
        "ember\n",
        "brynlee\n",
        "rowan\n",
        "joanna\n",
        "paige\n",
        "rebecca\n",
        "ana\n",
        "sawyer\n",
        "mariah\n",
        "nicole\n",
        "brooklynn\n",
        "payton\n",
        "marley\n",
        "fiona\n",
        "georgia\n",
        "lila\n",
        "harley\n",
        "adelyn\n",
        "alivia\n",
        "noelle\n",
        "gemma\n",
        "vanessa\n",
        "journey\n",
        "makayla\n",
        "angelina\n",
        "adaline\n",
        "catalina\n",
        "alayna\n",
        "julianna\n",
        "leila\n",
        "lola\n",
        "adriana\n",
        "june\n",
        "juliet\n",
        "jayla\n",
        "river\n",
        "tessa\n",
        "lia\n",
        "dakota\n",
        "delaney\n",
        "selena\n",
        "blakely\n",
        "ada\n",
        "camille\n",
        "zara\n",
        "malia\n",
        "hope\n",
        "samara\n",
        "vera\n",
        "mckenna\n",
        "briella\n",
        "izabella\n",
        "hayden\n",
        "raegan\n",
        "michelle\n",
        "angela\n",
        "ruth\n",
        "freya\n",
        "kamila\n",
        "vivienne\n",
        "aspen\n",
        "olive\n",
        "kendall\n",
        "elaina\n",
        "thea\n",
        "kali\n",
        "destiny\n",
        "amiyah\n",
        "evangeline\n",
        "cali\n",
        "blake\n",
        "elsie\n",
        "juniper\n",
        "alexandria\n",
        "myla\n",
        "ariella\n",
        "kate\n",
        "mariana\n",
        "lilah\n",
        "charlee\n",
        "daleyza\n",
        "nyla\n",
        "jane\n",
        "maggie\n",
        "zuri\n",
        "aniyah\n",
        "lucille\n",
        "leia\n",
        "melissa\n",
        "adelaide\n",
        "amina\n",
        "giselle\n",
        "lena\n",
        "camilla\n",
        "miriam\n",
        "millie\n",
        "brynn\n",
        "gabrielle\n",
        "sage\n",
        "annie\n",
        "logan\n",
        "lilliana\n",
        "haven\n",
        "jessica\n",
        "kaia\n",
        "magnolia\n",
        "amira\n",
        "adelynn\n",
        "makenzie\n",
        "stephanie\n",
        "nina\n",
        "phoebe\n",
        "arielle\n",
        "evie\n",
        "lyric\n",
        "alessandra\n",
        "gabriela\n",
        "paislee\n",
        "raelyn\n",
        "madilyn\n",
        "paris\n",
        "makenna\n",
        "kinley\n",
        "gracelyn\n",
        "talia\n",
        "maeve\n",
        "rylie\n",
        "kiara\n",
        "evelynn\n",
        "brinley\n",
        "jacqueline\n",
        "laura\n",
        "gracelynn\n",
        "lexi\n",
        "ariah\n",
        "fatima\n",
        "jennifer\n",
        "kehlani\n",
        "alani\n",
        "ariyah\n",
        "luciana\n",
        "allie\n",
        "heidi\n",
        "maci\n",
        "phoenix\n",
        "felicity\n",
        "joy\n",
        "kenzie\n",
        "veronica\n",
        "margot\n",
        "addilyn\n",
        "lana\n",
        "cassidy\n",
        "remington\n",
        "saylor\n",
        "ryan\n",
        "keira\n",
        "harlow\n",
        "miranda\n",
        "angel\n",
        "amanda\n",
        "daniella\n",
        "royalty\n",
        "gwendolyn\n",
        "ophelia\n",
        "heaven\n",
        "jordan\n",
        "madeleine\n",
        "esmeralda\n",
        "kira\n",
        "miracle\n",
        "elle\n",
        "amari\n",
        "danielle\n",
        "daphne\n",
        "willa\n",
        "haley\n",
        "gia\n",
        "kaitlyn\n",
        "oakley\n",
        "kailani\n",
        "winter\n",
        "alicia\n",
        "serena\n",
        "nadia\n",
        "aviana\n",
        "demi\n",
        "jada\n",
        "braelynn\n",
        "dylan\n",
        "ainsley\n",
        "alison\n",
        "camryn\n",
        "avianna\n",
        "bianca\n",
        "skyler\n",
        "scarlet\n",
        "maddison\n",
        "nylah\n",
        "sarai\n",
        "regina\n",
        "dahlia\n",
        "nayeli\n",
        "raven\n",
        "helen\n",
        "adrianna\n",
        "averie\n",
        "skye\n",
        "kelsey\n",
        "tatum\n",
        "kensley\n",
        "maliyah\n",
        "erin\n",
        "viviana\n",
        "jenna\n",
        "anaya\n",
        "carolina\n",
        "shelby\n",
        "sabrina\n",
        "mikayla\n",
        "annalise\n",
        "octavia\n",
        "lennon\n",
        "blair\n",
        "carmen\n",
        "yaretzi\n",
        "kennedi\n",
        "mabel\n",
        "zariah\n",
        "kyla\n",
        "christina\n",
        "selah\n",
        "celeste\n",
        "eve\n",
        "mckinley\n",
        "milani\n",
        "frances\n",
        "jimena\n",
        "kylee\n",
        "leighton\n",
        "katie\n",
        "aitana\n",
        "kayleigh\n",
        "sierra\n",
        "kathryn\n",
        "rosemary\n",
        "jolene\n",
        "alondra\n",
        "elisa\n",
        "helena\n",
        "charleigh\n",
        "hallie\n",
        "lainey\n",
        "avah\n",
        "jazlyn\n",
        " \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create SLP\n",
        "- parse words into token arrays => xs, ys\n",
        "- one hot encode xs into (n, 27) matrix\n",
        "- create randomized weights as hidden/output layer (27, 27)\n",
        "- perform matrix mult on input and output matrix\n",
        "- calculate loss through average negative log value"
      ],
      "metadata": {
        "id": "fAn2reM27pls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encode/decode functions\n",
        "\n",
        "chrs = sorted(list(set(string)))\n",
        "\n",
        "stoi = {chr: i for i, chr in enumerate(chrs[2:])}\n",
        "stoi[\".\"] = 26\n",
        "itos = {i: chr for chr, i in stoi.items()}\n",
        "\n",
        "def encode(str):\n",
        "  return [stoi[chr] for chr in str]\n",
        "\n",
        "def decode(nums):\n",
        "  return [itos[int(num)] for num in str(nums)]\n",
        "\n"
      ],
      "metadata": {
        "id": "oQKGPrG_9cQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seperate words into token arrays\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "words = string.splitlines()\n",
        "words = words[1: 10]\n",
        "# for word in words:\n",
        "word = [\".\"] + list(words[2]) + [\".\"]\n",
        "\n",
        "xs = encode(word)\n",
        "xs = torch.tensor(xs)\n",
        "xs_e = F.one_hot(xs).type(torch.float16)\n",
        "\n",
        "ys = xs\n",
        "\n",
        "xs_e, ys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WjVlHfvS8C2b",
        "outputId": "3ab1cbc1-4e8d-404f-8efa-fc18cb007760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=torch.float16),\n",
              " tensor([26,  0, 21,  0, 26]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create hidden layer\n",
        "\n",
        "slp = torch.rand((27, 27), dtype=torch.float16, requires_grad=True)\n",
        "\n",
        "# perform matrix mult\n",
        "output = xs_e @ slp\n",
        "\n",
        "xs_e[0], slp, output[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "v-Bqbx---lav",
        "outputId": "0c480191-c06b-4209-acef-97ea8ecc1da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=torch.float16),\n",
              " tensor([[0.4277, 0.6401, 0.7134, 0.3315, 0.7036, 0.3335, 0.5610, 0.7939, 0.6934,\n",
              "          0.8457, 0.1108, 0.5020, 0.5864, 0.5820, 0.5142, 0.2520, 0.2510, 0.5693,\n",
              "          0.3535, 0.7471, 0.1143, 0.6890, 0.0366, 0.1870, 0.5361, 0.8984, 0.9287],\n",
              "         [0.1987, 0.6509, 0.6206, 0.7114, 0.4321, 0.9814, 0.1099, 0.5142, 0.8813,\n",
              "          0.8472, 0.4688, 0.5405, 0.6714, 0.3169, 0.7241, 0.2090, 0.1191, 0.5083,\n",
              "          0.5098, 0.6045, 0.4326, 0.4980, 0.7095, 0.7520, 0.1538, 0.1382, 0.7720],\n",
              "         [0.9541, 0.3423, 0.5513, 0.6499, 0.9565, 0.1265, 0.3657, 0.2471, 0.4419,\n",
              "          0.4639, 0.1841, 0.8120, 0.6846, 0.5498, 0.6343, 0.3931, 0.6855, 0.3594,\n",
              "          0.7700, 0.4111, 0.1235, 0.3818, 0.5752, 0.6084, 0.9136, 0.5591, 0.6328],\n",
              "         [0.1104, 0.7925, 0.9204, 0.1479, 0.1191, 0.5498, 0.0698, 0.6968, 0.7085,\n",
              "          0.9229, 0.9546, 0.3511, 0.8110, 0.1772, 0.7993, 0.2910, 0.1538, 0.0669,\n",
              "          0.6343, 0.2285, 0.3457, 0.7690, 0.3350, 0.8926, 0.9702, 0.0244, 0.8965],\n",
              "         [0.1919, 0.9595, 0.7705, 0.5479, 0.5161, 0.1538, 0.7197, 0.3184, 0.9092,\n",
              "          0.7749, 0.0776, 0.5137, 0.8252, 0.0176, 0.6279, 0.7656, 0.4946, 0.5825,\n",
              "          0.1362, 0.0361, 0.6748, 0.8423, 0.1631, 0.6172, 0.9731, 0.6504, 0.7827],\n",
              "         [0.3364, 0.9858, 0.4341, 0.1587, 0.1533, 0.1362, 0.5708, 0.3203, 0.4004,\n",
              "          0.7544, 0.3086, 0.6274, 0.7139, 0.3896, 0.3154, 0.8481, 0.8652, 0.6304,\n",
              "          0.6494, 0.3940, 0.4204, 0.7168, 0.1558, 0.7007, 0.8574, 0.3018, 0.5210],\n",
              "         [0.5869, 0.1587, 0.9155, 0.1743, 0.1611, 0.5107, 0.7837, 0.6450, 0.4863,\n",
              "          0.7603, 0.4385, 0.9902, 0.8589, 0.4980, 0.7588, 0.4810, 0.4697, 0.1611,\n",
              "          0.1445, 0.4126, 0.7051, 0.7764, 0.1982, 0.6372, 0.3647, 0.9229, 0.9873],\n",
              "         [0.4619, 0.1035, 0.0605, 0.3354, 0.3574, 0.3066, 0.3896, 0.4375, 0.3354,\n",
              "          0.1865, 0.8892, 0.5679, 0.6865, 0.1973, 0.5557, 0.4194, 0.4209, 0.7617,\n",
              "          0.0747, 0.7832, 0.4229, 0.8379, 0.6396, 0.5864, 0.5850, 0.5264, 0.3491],\n",
              "         [0.9551, 0.8286, 0.5713, 0.1587, 0.4189, 0.1440, 0.1362, 0.8384, 0.1763,\n",
              "          0.2861, 0.1938, 0.5107, 0.0415, 0.6021, 0.3950, 0.5684, 0.5190, 0.9175,\n",
              "          0.1367, 0.8218, 0.5874, 0.5884, 0.5312, 0.5654, 0.1670, 0.3950, 0.2861],\n",
              "         [0.0698, 0.6504, 0.8408, 0.3354, 0.7319, 0.7744, 0.9229, 0.0957, 0.5376,\n",
              "          0.5776, 0.6709, 0.4048, 0.3311, 0.0649, 0.0771, 0.6069, 0.9941, 0.5610,\n",
              "          0.0850, 0.9077, 0.9780, 0.6719, 0.3315, 0.4966, 0.3887, 0.4360, 0.6167],\n",
              "         [0.1724, 0.3677, 0.6489, 0.0620, 0.2949, 0.8359, 0.1919, 0.8926, 0.0361,\n",
              "          0.3960, 0.0127, 0.1885, 0.2036, 0.2700, 0.4844, 0.2617, 0.8657, 0.5986,\n",
              "          0.6357, 0.8828, 0.9780, 0.4292, 0.1064, 0.7764, 0.6265, 0.2886, 0.2295],\n",
              "         [0.6650, 0.8833, 0.9492, 0.6792, 0.7729, 0.8418, 0.9907, 0.5127, 0.2563,\n",
              "          0.6992, 0.8340, 0.9985, 0.6460, 0.4253, 0.0767, 0.7241, 0.8232, 0.0405,\n",
              "          0.1475, 0.3984, 0.5605, 0.8589, 0.5654, 0.2690, 0.7051, 0.9033, 0.5884],\n",
              "         [0.4565, 0.2896, 0.5659, 0.5049, 0.7412, 0.3062, 0.1953, 0.8311, 0.4604,\n",
              "          0.4824, 0.2905, 0.9243, 0.7397, 0.6372, 0.5176, 0.7930, 0.5181, 0.3184,\n",
              "          0.0903, 0.4009, 0.8423, 0.2837, 0.9341, 0.0557, 0.6333, 0.7915, 0.8218],\n",
              "         [0.0933, 0.5137, 0.6992, 0.1621, 0.0371, 0.2227, 0.7222, 0.2725, 0.9131,\n",
              "          0.2173, 0.3193, 0.1035, 0.4844, 0.2163, 0.3462, 0.0088, 0.1602, 0.7983,\n",
              "          0.5093, 0.6245, 0.0449, 0.2725, 0.1084, 0.1772, 0.0845, 0.1621, 0.0127],\n",
              "         [0.3906, 0.6162, 0.1631, 0.0552, 0.1362, 0.5791, 0.2285, 0.6030, 0.4805,\n",
              "          0.8535, 0.5444, 0.3623, 0.2065, 0.7681, 0.1831, 0.1484, 0.5967, 0.5122,\n",
              "          0.0342, 0.5400, 0.0684, 0.4160, 0.2246, 0.5483, 0.2881, 0.6333, 0.1270],\n",
              "         [0.4062, 0.3931, 0.1108, 0.5015, 0.4272, 0.4673, 0.3691, 0.8721, 0.1104,\n",
              "          0.4248, 0.1108, 0.1572, 0.7480, 0.1162, 0.8833, 0.6577, 0.9346, 0.0874,\n",
              "          0.4673, 0.3438, 0.3486, 0.3921, 0.4072, 0.3789, 0.3896, 0.6982, 0.7910],\n",
              "         [0.3467, 0.7729, 0.9453, 0.0908, 0.8438, 0.9473, 0.6738, 0.7866, 0.8760,\n",
              "          0.6226, 0.7266, 0.3501, 0.0103, 0.6533, 0.4536, 0.9102, 0.6392, 0.4453,\n",
              "          0.4580, 0.0454, 0.6572, 0.9512, 0.6440, 0.1304, 0.5039, 0.2852, 0.4604],\n",
              "         [0.6260, 0.7456, 0.0767, 0.2886, 0.3833, 0.8418, 0.2080, 0.1699, 0.7524,\n",
              "          0.0889, 0.0093, 0.9668, 0.2129, 0.1909, 0.2476, 0.5112, 0.9448, 0.5010,\n",
              "          0.4355, 0.2749, 0.4512, 0.7466, 0.6226, 0.5332, 0.7402, 0.2827, 0.2241],\n",
              "         [0.7563, 0.7500, 0.1426, 0.4121, 0.2544, 0.8018, 0.2954, 0.4673, 0.4863,\n",
              "          0.6338, 0.8960, 0.7446, 0.6973, 0.8813, 0.9585, 0.9609, 0.9785, 0.8989,\n",
              "          0.8901, 0.3438, 0.7803, 0.1680, 0.6172, 0.9399, 0.9028, 0.2412, 0.8745],\n",
              "         [0.0239, 0.9912, 0.2954, 0.0308, 0.7905, 0.5063, 0.4155, 0.9321, 0.9561,\n",
              "          0.2114, 0.7627, 0.3462, 0.9985, 0.3921, 0.1665, 0.1025, 0.1221, 0.7305,\n",
              "          0.3062, 0.5234, 0.8745, 0.7627, 0.7354, 0.2002, 0.3003, 0.8950, 0.9106],\n",
              "         [0.5430, 0.8423, 0.3066, 0.2627, 0.5840, 0.9033, 0.6270, 0.1152, 0.1665,\n",
              "          0.0527, 0.9287, 0.7861, 0.0967, 0.0991, 0.8608, 0.6333, 0.3936, 0.6548,\n",
              "          0.6382, 0.9507, 0.0806, 0.7075, 0.5273, 0.3140, 0.0083, 0.7852, 0.6597],\n",
              "         [0.1602, 0.2173, 0.7100, 0.9966, 0.7295, 0.5093, 0.4795, 0.7329, 0.7915,\n",
              "          0.8027, 0.4727, 0.3008, 0.7349, 0.7710, 0.8423, 0.2705, 0.7871, 0.3716,\n",
              "          0.2476, 0.7119, 0.9756, 0.1104, 0.6665, 0.9482, 0.8721, 0.5435, 0.0137],\n",
              "         [0.4541, 0.4561, 0.3540, 0.1729, 0.8228, 0.9995, 0.4771, 0.4326, 0.5864,\n",
              "          0.1553, 0.7266, 0.9106, 0.0581, 0.9712, 0.7510, 0.2979, 0.1851, 0.0532,\n",
              "          0.3589, 0.4517, 0.4097, 0.0562, 0.8711, 0.5210, 0.1494, 0.8408, 0.8608],\n",
              "         [0.2061, 0.8799, 0.8774, 0.2783, 0.8921, 0.0234, 0.4536, 0.1431, 0.2300,\n",
              "          0.6738, 0.7998, 0.8262, 0.5645, 0.7446, 0.6650, 0.2607, 0.2783, 0.6631,\n",
              "          0.2378, 0.1440, 0.2222, 0.3120, 0.2056, 0.6357, 0.3511, 0.3032, 0.6514],\n",
              "         [0.2681, 0.9761, 0.5630, 0.3677, 0.0103, 0.0352, 0.8062, 0.2534, 0.0205,\n",
              "          0.8545, 0.4531, 0.4443, 0.2378, 0.1016, 0.8154, 0.2290, 0.0342, 0.9229,\n",
              "          0.2983, 0.4282, 0.9702, 0.1685, 0.7993, 0.6646, 0.7974, 0.1201, 0.8789],\n",
              "         [0.5625, 0.5601, 0.7329, 0.8535, 0.9116, 0.6694, 0.5327, 0.8794, 0.4780,\n",
              "          0.5767, 0.2637, 0.9019, 0.2866, 0.3960, 0.9795, 0.5903, 0.5303, 0.8169,\n",
              "          0.0039, 0.4106, 0.5088, 0.9307, 0.8262, 0.0039, 0.4683, 0.0127, 0.0435],\n",
              "         [0.9585, 0.3721, 0.4097, 0.0273, 0.1533, 0.0337, 0.1880, 0.6025, 0.4600,\n",
              "          0.5078, 0.0547, 0.1094, 0.3047, 0.7295, 0.4263, 0.2090, 0.3076, 0.2671,\n",
              "          0.9292, 0.0151, 0.9980, 0.5054, 0.3159, 0.9346, 0.0625, 0.1948, 0.1616]],\n",
              "        dtype=torch.float16, requires_grad=True),\n",
              " tensor([0.9585, 0.3721, 0.4097, 0.0273, 0.1533, 0.0337, 0.1880, 0.6025, 0.4600,\n",
              "         0.5078, 0.0547, 0.1094, 0.3047, 0.7295, 0.4263, 0.2090, 0.3076, 0.2671,\n",
              "         0.9292, 0.0151, 0.9980, 0.5054, 0.3159, 0.9346, 0.0625, 0.1948, 0.1616],\n",
              "        dtype=torch.float16, grad_fn=<SelectBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# combining\n",
        "\n",
        "words = string.splitlines()\n",
        "words = words[1: 9]\n",
        "\n",
        "for word in words:\n",
        "  word = [\".\"] + list(word) + [\".\"]\n",
        "  xs = encode(word)\n",
        "  xs = torch.tensor(xs)\n",
        "  xs_e = F.one_hot(xs).type(torch.float16)\n",
        "  xs_e = xs_e[:-1]\n",
        "  ys = xs[1:]\n",
        "  # print(f\"{word}:\\n\\n xs - {xs},\\n\\n xs_e - {xs_e},\\n\\n ys - {ys}\\n\\n\")\n",
        "\n",
        "  # matrix mult\n",
        "  output = xs_e @ slp\n",
        "  output /= torch.sum(output, 1, keepdims=True)\n",
        "  # print(output)\n",
        "  loss = 0\n",
        "  loss_count = 0\n",
        "  for y in range(len(ys)):\n",
        "    loss += -torch.log(output[y][ys[y]])\n",
        "    loss_count += 1\n",
        "    # print(output[y][ys[y]], loss)\n",
        "  print(loss / loss_count)\n",
        "\n",
        "  # backprop\n",
        "  slp.grad = None\n",
        "  loss.backward()\n",
        "  slp.data += -0.1 * slp.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WtF-HFRUAzRz",
        "outputId": "f8b71a65-5d61-429a-acce-83b91612f3ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.2402, dtype=torch.float16, grad_fn=<DivBackward0>)\n",
            "tensor(3.1387, dtype=torch.float16, grad_fn=<DivBackward0>)\n",
            "tensor(3.1426, dtype=torch.float16, grad_fn=<DivBackward0>)\n",
            "tensor(3.2715, dtype=torch.float16, grad_fn=<DivBackward0>)\n",
            "tensor(2.9688, dtype=torch.float16, grad_fn=<DivBackward0>)\n",
            "tensor(3.4316, dtype=torch.float16, grad_fn=<DivBackward0>)\n",
            "tensor(2.9824, dtype=torch.float16, grad_fn=<DivBackward0>)\n",
            "tensor(2.8008, dtype=torch.float16, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    }
  ]
}