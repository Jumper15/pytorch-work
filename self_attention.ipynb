{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP04ff0mO6FGoBCURXKKXlk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jumper15/pytorch-work/blob/main/self_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z32_10Y3g8lr"
      },
      "outputs": [],
      "source": [
        "# !pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BEK6OOkwUYM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# torch.manual_seed(1337)\n",
        "# B, T, C = 4, 8, 1\n",
        "# x = torch.randn(B, T, C)\n",
        "# for b in range(B):\n",
        "#   for t in range(T):\n",
        "#     xbow = x[b, 0:t+1]\n",
        "#     sum = torch.sum(xbow, dim=0)\n",
        "#     print(sum)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayjpdZWY5J1y",
        "outputId": "aaec2ef2-9283-47df-9c39-b3478ec8d369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1808])\n",
            "tensor([0.1108])\n",
            "tensor([-0.2488])\n",
            "tensor([-1.1640])\n",
            "tensor([-0.5383])\n",
            "tensor([-0.5128])\n",
            "tensor([0.4417])\n",
            "tensor([0.5061])\n",
            "tensor([0.3612])\n",
            "tensor([1.5290])\n",
            "tensor([0.1791])\n",
            "tensor([-0.3310])\n",
            "tensor([-0.0951])\n",
            "tensor([-0.3349])\n",
            "tensor([-1.2560])\n",
            "tensor([0.2873])\n",
            "tensor([1.3488])\n",
            "tensor([1.2092])\n",
            "tensor([1.4950])\n",
            "tensor([2.4601])\n",
            "tensor([0.4230])\n",
            "tensor([0.9161])\n",
            "tensor([2.4031])\n",
            "tensor([2.9941])\n",
            "tensor([0.1260])\n",
            "tensor([-1.4367])\n",
            "tensor([-2.5968])\n",
            "tensor([-2.9316])\n",
            "tensor([-2.4838])\n",
            "tensor([-3.2855])\n",
            "tensor([-1.7619])\n",
            "tensor([0.7467])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.manual_seed(6767)\n",
        "# tril = torch.tril(torch.ones(3, 3))\n",
        "# m = torch.rand((2,3))\n",
        "# t = m.T\n",
        "# # sum = tril @ t\n",
        "# sum = m @ tril\n",
        "# m, tril, sum\n"
      ],
      "metadata": {
        "id": "8gSGZaUQYCIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.manual_seed(1337)\n",
        "# B, T, C = 4, 8, 1\n",
        "# x = torch.randn(B, T, C)\n",
        "# tril = torch.tril(torch.ones(4, 8, 8))\n",
        "# m = x[0].T @ tril[0]\n",
        "# tril[0], x[0].view(-1), m"
      ],
      "metadata": {
        "id": "RW7mq3mxTTZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tril = torch.tril(torch.ones(3,4))\n",
        "# tril = tril / torch.sum(tril, dim=1, keepdims=True)\n",
        "# tril"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3FV4VSVc0Tw",
        "outputId": "530ea133-3b54-4866-e7b7-96e76d2d19c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# key, query, value\n",
        "# n_dims = 16\n",
        "# B, T, C = 4, 8, 2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "torch.manual_seed(676767)\n",
        "\n",
        "B, T, C = 4, 8, 2\n",
        "embed_dims = 32\n",
        "\n",
        "# for one batch\n",
        "input = torch.randint(8, (B, T, C)) # TC: 4, 8, 2\n",
        "Embed = nn.Embedding(8, embed_dims) # embeds: 4, 8, 2, 32\n",
        "# input, Embed(input)\n",
        "embed = Embed(input)\n",
        "embed = embed.view(B, T, -1)\n",
        "ln1 = nn.Linear(embed_dims*C, C)\n",
        "logits = ln1(embed)\n",
        "\n",
        "input.shape, embed.shape, logits.shape\n"
      ],
      "metadata": {
        "id": "_mV5-SAw9zjQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd409505-044b-43a0-ade7-d210a6d53558"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 8, 2]), torch.Size([4, 8, 64]), torch.Size([4, 8, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(676767)\n",
        "\n",
        "# attention block\n",
        "head_size = 16\n",
        "\n",
        "# value_layer = nn.Linear(C, head_size)\n",
        "key_layer = nn.Linear(C, head_size)\n",
        "query_layer = nn.Linear(C, head_size)\n",
        "\n",
        "keys = key_layer(logits)\n",
        "querys = query_layer(logits)\n",
        "attention_block = keys @ querys.transpose(-1, -2)\n",
        "attention_block.shape, attention_block[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BHFXuc5GZzW",
        "outputId": "555fc282-8031-4a3d-a7b7-8d1b672347f0"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 8, 8]),\n",
              " tensor([[ 0.2850,  0.7048,  0.6008,  0.2850,  0.5184,  1.0615,  0.5184,  0.5212],\n",
              "         [ 0.8059,  1.3491,  0.5115,  0.8059,  0.3369,  1.8481,  0.3369,  0.0242],\n",
              "         [ 0.2421,  0.6112, -0.3186,  0.2421, -0.4721,  0.9696, -0.4721, -0.8469],\n",
              "         [ 0.2850,  0.7048,  0.6008,  0.2850,  0.5184,  1.0615,  0.5184,  0.5212],\n",
              "         [ 0.0979,  0.4289, -0.3835,  0.0979, -0.5192,  0.7491, -0.5192, -0.8456],\n",
              "         [ 1.2717,  1.9274,  0.4811,  1.2717,  0.2283,  2.5531,  0.2283, -0.3450],\n",
              "         [ 0.0979,  0.4289, -0.3835,  0.0979, -0.5192,  0.7491, -0.5192, -0.8456],\n",
              "         [-0.0943,  0.1730, -0.7676, -0.0943, -0.9046,  0.4467, -0.9046, -1.2963]],\n",
              "        grad_fn=<SelectBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(676767)\n",
        "\n",
        "# tril\n",
        "sfmx = nn.Softmax(dim=2)\n",
        "masked_tril = attention_block.masked_fill(torch.tril(torch.ones(4, 8, 8)) == 0, float('-inf'))\n",
        "output = sfmx(masked_tril)\n",
        "attention_block[0], masked_tril[0], output[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYZNqZMHIz4r",
        "outputId": "1ab98785-8c9e-43de-933a-ebed2e0c895b"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.2850,  0.7048,  0.6008,  0.2850,  0.5184,  1.0615,  0.5184,  0.5212],\n",
              "         [ 0.8059,  1.3491,  0.5115,  0.8059,  0.3369,  1.8481,  0.3369,  0.0242],\n",
              "         [ 0.2421,  0.6112, -0.3186,  0.2421, -0.4721,  0.9696, -0.4721, -0.8469],\n",
              "         [ 0.2850,  0.7048,  0.6008,  0.2850,  0.5184,  1.0615,  0.5184,  0.5212],\n",
              "         [ 0.0979,  0.4289, -0.3835,  0.0979, -0.5192,  0.7491, -0.5192, -0.8456],\n",
              "         [ 1.2717,  1.9274,  0.4811,  1.2717,  0.2283,  2.5531,  0.2283, -0.3450],\n",
              "         [ 0.0979,  0.4289, -0.3835,  0.0979, -0.5192,  0.7491, -0.5192, -0.8456],\n",
              "         [-0.0943,  0.1730, -0.7676, -0.0943, -0.9046,  0.4467, -0.9046, -1.2963]],\n",
              "        grad_fn=<SelectBackward0>),\n",
              " tensor([[ 0.2850,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
              "         [ 0.8059,  1.3491,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
              "         [ 0.2421,  0.6112, -0.3186,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
              "         [ 0.2850,  0.7048,  0.6008,  0.2850,    -inf,    -inf,    -inf,    -inf],\n",
              "         [ 0.0979,  0.4289, -0.3835,  0.0979, -0.5192,    -inf,    -inf,    -inf],\n",
              "         [ 1.2717,  1.9274,  0.4811,  1.2717,  0.2283,  2.5531,    -inf,    -inf],\n",
              "         [ 0.0979,  0.4289, -0.3835,  0.0979, -0.5192,  0.7491, -0.5192,    -inf],\n",
              "         [-0.0943,  0.1730, -0.7676, -0.0943, -0.9046,  0.4467, -0.9046, -1.2963]],\n",
              "        grad_fn=<SelectBackward0>),\n",
              " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.3674, 0.6326, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.3314, 0.4794, 0.1892, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.2044, 0.3110, 0.2803, 0.2044, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.2198, 0.3060, 0.1358, 0.2198, 0.1186, 0.0000, 0.0000, 0.0000],\n",
              "         [0.1200, 0.2312, 0.0544, 0.1200, 0.0423, 0.4322, 0.0000, 0.0000],\n",
              "         [0.1427, 0.1987, 0.0882, 0.1427, 0.0770, 0.2737, 0.0770, 0.0000],\n",
              "         [0.1487, 0.1943, 0.0759, 0.1487, 0.0661, 0.2555, 0.0661, 0.0447]],\n",
              "        grad_fn=<SelectBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "torch.manual_seed(676767)\n",
        "\n",
        "class Attention_Head():\n",
        "  def __init__(self, head_size=16, embed_dims=32):\n",
        "    self.head_size = head_size\n",
        "    self.embed_dims = embed_dims\n",
        "\n",
        "    self.Embed = nn.Embedding(8, embed_dims)\n",
        "\n",
        "  def masked_tril(self, logits):\n",
        "    sfmx = nn.Softmax(dim=2)\n",
        "    masked_tril = logits.masked_fill(torch.tril(torch.ones(4, 8, 8)) == 0, float('-inf'))\n",
        "    output = sfmx(masked_tril)\n",
        "    return output\n",
        "\n",
        "  def self_attention(self, input):\n",
        "    # B, T, C = 4, 8, 2\n",
        "    B, T, C = input.shape\n",
        "\n",
        "    # for one batch\n",
        "    # Embed = nn.Embedding(8, embed_dims) # embeds: 4, 8, 2, 32\n",
        "    # input, Embed(input)\n",
        "    embed = self.Embed(input)\n",
        "    embed = embed.view(B, T, -1)\n",
        "    ln1 = nn.Linear(self.embed_dims*C, C)\n",
        "    logits = ln1(embed)\n",
        "\n",
        "    # attention block\n",
        "    head_size = 16\n",
        "\n",
        "    # value_layer = nn.Linear(C, head_size)\n",
        "    key_layer = nn.Linear(C, self.head_size)\n",
        "    query_layer = nn.Linear(C, self.head_size)\n",
        "\n",
        "    keys = key_layer(logits)\n",
        "    querys = query_layer(logits)\n",
        "    attention_block = keys @ querys.transpose(-1, -2)\n",
        "    attention_block.shape, attention_block[0]\n",
        "\n",
        "    # tril\n",
        "    # sfmx = nn.Softmax(dim=2)\n",
        "    # masked_tril = attention_block.masked_fill(torch.tril(torch.ones(4, 8, 8)) == 0, float('-inf'))\n",
        "    # output = sfmx(masked_tril)\n",
        "    # attention_block[0], masked_tril[0], output[0]\n",
        "\n",
        "\n",
        "\n",
        "    input = torch.randint(8, (B, T, C)) # TC: 4, 8, 2\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "P5siqXsnRA9m",
        "outputId": "fe903d75-dea9-4381-b74e-6bd9bba7fb83"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after function definition on line 12 (ipython-input-1212774688.py, line 14)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1212774688.py\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    def self_attention(self, input):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LvEwTEBjRoTV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}