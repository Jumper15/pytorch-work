{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNrGCdVruCsQcusYFlqbjMy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jumper15/pytorch-work/blob/main/self_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.manual_seed(6767)\n",
        "# tril = torch.tril(torch.ones(3, 3))\n",
        "# m = torch.rand((2,3))\n",
        "# t = m.T\n",
        "# # sum = tril @ t\n",
        "# sum = m @ tril\n",
        "# m, tril, sum\n"
      ],
      "metadata": {
        "id": "8gSGZaUQYCIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.manual_seed(1337)\n",
        "# B, T, C = 4, 8, 1\n",
        "# x = torch.randn(B, T, C)\n",
        "# tril = torch.tril(torch.ones(4, 8, 8))\n",
        "# m = x[0].T @ tril[0]\n",
        "# tril[0], x[0].view(-1), m"
      ],
      "metadata": {
        "id": "RW7mq3mxTTZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tril = torch.tril(torch.ones(3,4))\n",
        "# tril = tril / torch.sum(tril, dim=1, keepdims=True)\n",
        "# tril"
      ],
      "metadata": {
        "id": "V3FV4VSVc0Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# key, query, value\n",
        "# n_dims = 16\n",
        "# B, T, C = 4, 8, 2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "torch.manual_seed(676767)\n",
        "\n",
        "B, T, C = 4, 8, 2\n",
        "embed_dims = 32\n",
        "\n",
        "# for one batch\n",
        "input = torch.randint(8, (B, T, C)) # TC: 4, 8, 2\n",
        "Embed = nn.Embedding(8, embed_dims) # embeds: 4, 8, 2, 32\n",
        "# input, Embed(input)\n",
        "embed = Embed(input)\n",
        "embed = embed.view(B, T, -1)\n",
        "ln1 = nn.Linear(embed_dims*C, C)\n",
        "logits = ln1(embed)\n",
        "\n",
        "input.shape, embed.shape, logits.shape\n"
      ],
      "metadata": {
        "id": "_mV5-SAw9zjQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c71543b-3be3-4dcc-fd3c-910673f14d22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 8, 2]), torch.Size([4, 8, 64]), torch.Size([4, 8, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(676767)\n",
        "\n",
        "# attention block\n",
        "head_size = 16\n",
        "\n",
        "# value_layer = nn.Linear(C, head_size)\n",
        "key_layer = nn.Linear(C, head_size)\n",
        "query_layer = nn.Linear(C, head_size)\n",
        "\n",
        "keys = key_layer(logits)\n",
        "querys = query_layer(logits)\n",
        "attention_block = keys @ querys.transpose(-1, -2)\n",
        "attention_block.shape, attention_block[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BHFXuc5GZzW",
        "outputId": "9bd5bef5-aa99-44be-a5cc-3514e156decf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 8, 8]),\n",
              " tensor([[ 0.2850,  0.7048,  0.6008,  0.2850,  0.5184,  1.0615,  0.5184,  0.5212],\n",
              "         [ 0.8059,  1.3491,  0.5115,  0.8059,  0.3369,  1.8481,  0.3369,  0.0242],\n",
              "         [ 0.2421,  0.6112, -0.3186,  0.2421, -0.4721,  0.9696, -0.4721, -0.8469],\n",
              "         [ 0.2850,  0.7048,  0.6008,  0.2850,  0.5184,  1.0615,  0.5184,  0.5212],\n",
              "         [ 0.0979,  0.4289, -0.3835,  0.0979, -0.5192,  0.7491, -0.5192, -0.8456],\n",
              "         [ 1.2717,  1.9274,  0.4811,  1.2717,  0.2283,  2.5531,  0.2283, -0.3450],\n",
              "         [ 0.0979,  0.4289, -0.3835,  0.0979, -0.5192,  0.7491, -0.5192, -0.8456],\n",
              "         [-0.0943,  0.1730, -0.7676, -0.0943, -0.9046,  0.4467, -0.9046, -1.2963]],\n",
              "        grad_fn=<SelectBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(676767)\n",
        "\n",
        "# tril\n",
        "sfmx = nn.Softmax(dim=2)\n",
        "masked_tril = attention_block.masked_fill(torch.tril(torch.ones(4, 8, 8)) == 0, float('-inf'))\n",
        "output = sfmx(masked_tril)\n",
        "attention_block[0], masked_tril[0], output[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYZNqZMHIz4r",
        "outputId": "80ba895c-d883-45bd-aff9-b1a8f147faed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.2850,  0.7048,  0.6008,  0.2850,  0.5184,  1.0615,  0.5184,  0.5212],\n",
              "         [ 0.8059,  1.3491,  0.5115,  0.8059,  0.3369,  1.8481,  0.3369,  0.0242],\n",
              "         [ 0.2421,  0.6112, -0.3186,  0.2421, -0.4721,  0.9696, -0.4721, -0.8469],\n",
              "         [ 0.2850,  0.7048,  0.6008,  0.2850,  0.5184,  1.0615,  0.5184,  0.5212],\n",
              "         [ 0.0979,  0.4289, -0.3835,  0.0979, -0.5192,  0.7491, -0.5192, -0.8456],\n",
              "         [ 1.2717,  1.9274,  0.4811,  1.2717,  0.2283,  2.5531,  0.2283, -0.3450],\n",
              "         [ 0.0979,  0.4289, -0.3835,  0.0979, -0.5192,  0.7491, -0.5192, -0.8456],\n",
              "         [-0.0943,  0.1730, -0.7676, -0.0943, -0.9046,  0.4467, -0.9046, -1.2963]],\n",
              "        grad_fn=<SelectBackward0>),\n",
              " tensor([[ 0.2850,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
              "         [ 0.8059,  1.3491,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
              "         [ 0.2421,  0.6112, -0.3186,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
              "         [ 0.2850,  0.7048,  0.6008,  0.2850,    -inf,    -inf,    -inf,    -inf],\n",
              "         [ 0.0979,  0.4289, -0.3835,  0.0979, -0.5192,    -inf,    -inf,    -inf],\n",
              "         [ 1.2717,  1.9274,  0.4811,  1.2717,  0.2283,  2.5531,    -inf,    -inf],\n",
              "         [ 0.0979,  0.4289, -0.3835,  0.0979, -0.5192,  0.7491, -0.5192,    -inf],\n",
              "         [-0.0943,  0.1730, -0.7676, -0.0943, -0.9046,  0.4467, -0.9046, -1.2963]],\n",
              "        grad_fn=<SelectBackward0>),\n",
              " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.3674, 0.6326, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.3314, 0.4794, 0.1892, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.2044, 0.3110, 0.2803, 0.2044, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.2198, 0.3060, 0.1358, 0.2198, 0.1186, 0.0000, 0.0000, 0.0000],\n",
              "         [0.1200, 0.2312, 0.0544, 0.1200, 0.0423, 0.4322, 0.0000, 0.0000],\n",
              "         [0.1427, 0.1987, 0.0882, 0.1427, 0.0770, 0.2737, 0.0770, 0.0000],\n",
              "         [0.1487, 0.1943, 0.0759, 0.1487, 0.0661, 0.2555, 0.0661, 0.0447]],\n",
              "        grad_fn=<SelectBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "torch.manual_seed(676767)\n",
        "\n",
        "class Attention_Head(nn.Module):\n",
        "  def __init__(self, head_size=16, embed_dims=32, B=4, T=8, C=2):\n",
        "    super().__init__()\n",
        "    self.head_size = head_size\n",
        "    self.embed_dims = embed_dims\n",
        "    self.Embed = nn.Embedding(64, embed_dims)\n",
        "    self.value_layer = nn.Linear(C, self.head_size)\n",
        "    self.key_layer = nn.Linear(C, self.head_size)\n",
        "    self.query_layer = nn.Linear(C, self.head_size)\n",
        "    self.ln1 = nn.Linear(self.embed_dims*C, C)\n",
        "\n",
        "  def masked_tril(self, logits):\n",
        "    sfmx = nn.Softmax(dim=2)\n",
        "    masked_tril = logits.masked_fill(torch.tril(torch.ones(4, 8, 8)) == 0, float('-inf'))\n",
        "    output = sfmx(masked_tril)\n",
        "    return output\n",
        "\n",
        "  def self_attention(self, input):\n",
        "\n",
        "    # input matrix embedding\n",
        "    embed = self.Embed(input)\n",
        "    embed = embed.view(B, T, -1)\n",
        "    logits = self.ln1(embed)\n",
        "\n",
        "    # attention block\n",
        "    keys = self.key_layer(logits)\n",
        "    querys = self.query_layer(logits)\n",
        "    values = self.value_layer(logits)\n",
        "    attention_block = keys @ querys.transpose(-1, -2)\n",
        "\n",
        "    output = self.masked_tril(attention_block)\n",
        "    output = output @ values\n",
        "    print(output)\n",
        "    return output\n",
        "\n",
        "    # tril\n",
        "    # sfmx = nn.Softmax(dim=2)\n",
        "    # masked_tril = attention_block.masked_fill(torch.tril(torch.ones(4, 8, 8)) == 0, float('-inf'))\n",
        "    # output = sfmx(masked_tril)\n",
        "    # attention_block[0], masked_tril[0], output[0]\n",
        "\n",
        "\n",
        "single_head = Attention_Head()\n",
        "B, T, C = 4, 8, 2\n",
        "input = torch.randint(8, (B, T, C)) # TC: 4, 8, 2\n",
        "\n",
        "output = single_head.self_attention(input)\n",
        "output.shape\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P5siqXsnRA9m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cdeed32-6c40-4913-c0c2-cfcee5eea61d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 4.9691e-01,  6.5349e-01, -1.3440e+00,  2.0494e-01,  5.4951e-01,\n",
            "          -7.2337e-01, -3.6584e-03, -9.5597e-01, -5.8277e-01, -8.8173e-02,\n",
            "          -1.1868e+00, -1.6801e-01, -7.6845e-01, -6.6694e-01,  3.9907e-01,\n",
            "           1.0695e+00],\n",
            "         [ 5.2738e-01,  4.4679e-01, -1.1983e+00,  1.8514e-01,  3.8327e-01,\n",
            "          -6.4634e-01,  8.9988e-02, -8.7577e-01, -4.8380e-01, -1.0956e-02,\n",
            "          -1.0179e+00, -2.5337e-01, -7.2716e-01, -5.8742e-01,  3.9445e-01,\n",
            "           9.3410e-01],\n",
            "         [ 7.1315e-01,  1.0322e-01, -9.0516e-01,  1.5128e-02,  8.8389e-02,\n",
            "          -5.6959e-01,  2.9841e-01, -6.7618e-01, -3.5978e-01,  8.5501e-02,\n",
            "          -7.4111e-01, -4.3633e-01, -7.6925e-01, -4.6017e-01,  5.1574e-01,\n",
            "           7.4633e-01],\n",
            "         [ 4.6912e-01,  3.7501e-01, -1.1737e+00,  2.4812e-01,  3.3501e-01,\n",
            "          -5.9347e-01,  9.5622e-02, -8.8167e-01, -4.2881e-01,  3.2106e-02,\n",
            "          -9.5728e-01, -2.6208e-01, -6.5640e-01, -5.5730e-01,  3.2713e-01,\n",
            "           8.6813e-01],\n",
            "         [ 4.2063e-01,  3.1054e-01, -1.1501e+00,  3.0079e-01,  2.9113e-01,\n",
            "          -5.4743e-01,  1.0218e-01, -8.8510e-01, -3.8057e-01,  6.9878e-02,\n",
            "          -9.0293e-01, -2.7107e-01, -5.9599e-01, -5.3039e-01,  2.7033e-01,\n",
            "           8.0993e-01],\n",
            "         [ 4.9700e-01,  1.9537e-02, -9.3238e-01,  2.3896e-01,  5.2487e-02,\n",
            "          -4.5168e-01,  2.4709e-01, -7.5577e-01, -2.5126e-01,  1.7069e-01,\n",
            "          -6.6614e-01, -4.0142e-01, -5.6528e-01, -4.1966e-01,  2.9577e-01,\n",
            "           6.2858e-01],\n",
            "         [ 5.7677e-01, -1.5555e-01, -7.8860e-01,  1.6743e-01, -9.5744e-02,\n",
            "          -4.0692e-01,  3.4749e-01, -6.6136e-01, -1.8360e-01,  2.2336e-01,\n",
            "          -5.2464e-01, -4.9014e-01, -5.7452e-01, -3.5427e-01,  3.4337e-01,\n",
            "           5.2879e-01],\n",
            "         [ 6.5670e-01, -3.1240e-01, -6.5661e-01,  9.4762e-02, -2.2970e-01,\n",
            "          -3.7003e-01,  4.4074e-01, -5.7264e-01, -1.2552e-01,  2.6855e-01,\n",
            "          -3.9813e-01, -5.7218e-01, -5.8974e-01, -2.9600e-01,  3.9409e-01,\n",
            "           4.4172e-01]],\n",
            "\n",
            "        [[ 8.7496e-01, -4.9616e-01, -4.5496e-01, -1.1682e-01, -4.0376e-01,\n",
            "          -3.7411e-01,  5.9865e-01, -4.0758e-01, -9.4806e-02,  2.9207e-01,\n",
            "          -2.5352e-01, -7.0619e-01, -7.0970e-01, -2.3226e-01,  5.7246e-01,\n",
            "           3.7405e-01],\n",
            "         [ 7.0726e-01, -3.9837e-01, -5.8172e-01,  4.8090e-02, -3.0404e-01,\n",
            "          -3.5237e-01,  4.9449e-01, -5.2070e-01, -9.5706e-02,  2.9172e-01,\n",
            "          -3.2898e-01, -6.1920e-01, -6.0361e-01, -2.6431e-01,  4.2833e-01,\n",
            "           3.9586e-01],\n",
            "         [ 8.3242e-01,  8.2474e-03, -7.9850e-01, -1.0079e-01, -2.4640e-03,\n",
            "          -5.7415e-01,  3.8256e-01, -5.8770e-01, -3.4584e-01,  9.6135e-02,\n",
            "          -6.6655e-01, -5.0756e-01, -8.3654e-01, -4.2746e-01,  6.1411e-01,\n",
            "           7.1313e-01],\n",
            "         [ 6.7749e-01,  2.6287e-01, -1.0223e+00,  4.2717e-02,  2.1845e-01,\n",
            "          -6.2449e-01,  2.2135e-01, -7.4408e-01, -4.3259e-01,  2.8721e-02,\n",
            "          -8.7120e-01, -3.6672e-01, -7.9121e-01, -5.2114e-01,  5.0774e-01,\n",
            "           8.4754e-01],\n",
            "         [ 8.6370e-01,  1.0477e-01, -8.4937e-01, -1.3772e-01,  6.8913e-02,\n",
            "          -6.2740e-01,  3.5660e-01, -6.0284e-01, -4.0569e-01,  4.9334e-02,\n",
            "          -7.4673e-01, -4.8154e-01, -8.9312e-01, -4.6625e-01,  6.5970e-01,\n",
            "           7.8888e-01],\n",
            "         [ 8.1202e-01,  1.6438e-01, -9.0756e-01, -8.8490e-02,  1.2274e-01,\n",
            "          -6.3333e-01,  3.1284e-01, -6.4700e-01, -4.2138e-01,  3.7191e-02,\n",
            "          -7.9419e-01, -4.4388e-01, -8.6988e-01, -4.8762e-01,  6.2010e-01,\n",
            "           8.1610e-01],\n",
            "         [ 8.8321e-01,  7.3945e-02, -8.2199e-01, -1.5586e-01,  4.2061e-02,\n",
            "          -6.2159e-01,  3.7641e-01, -5.8354e-01, -3.9541e-01,  5.7319e-02,\n",
            "          -7.2198e-01, -4.9882e-01, -8.9923e-01, -4.5494e-01,  6.7330e-01,\n",
            "           7.7282e-01],\n",
            "         [ 9.3409e-01,  1.7938e-01, -8.7125e-01, -2.1316e-01,  1.1773e-01,\n",
            "          -6.8609e-01,  3.5459e-01, -5.9187e-01, -4.6580e-01,  2.2531e-03,\n",
            "          -8.1004e-01, -4.7547e-01, -9.7473e-01, -4.9791e-01,  7.3907e-01,\n",
            "           8.6016e-01]],\n",
            "\n",
            "        [[ 7.9602e-01, -4.2617e-01, -5.3018e-01, -4.0479e-02, -3.3804e-01,\n",
            "          -3.7414e-01,  5.4014e-01, -4.6840e-01, -1.0776e-01,  2.8213e-01,\n",
            "          -3.0872e-01, -6.5642e-01, -6.6744e-01, -2.5669e-01,  5.0852e-01,\n",
            "           4.0098e-01],\n",
            "         [ 9.3109e-01, -2.6229e-01, -5.8562e-01, -1.8635e-01, -2.2812e-01,\n",
            "          -4.9565e-01,  5.2808e-01, -4.5390e-01, -2.3392e-01,  1.8332e-01,\n",
            "          -4.4721e-01, -6.3716e-01, -8.3067e-01, -3.2553e-01,  6.6418e-01,\n",
            "           5.5217e-01],\n",
            "         [ 8.1816e-01, -1.9112e-01, -6.7444e-01, -7.5594e-02, -1.5680e-01,\n",
            "          -4.8329e-01,  4.5583e-01, -5.3175e-01, -2.3731e-01,  1.8091e-01,\n",
            "          -5.0240e-01, -5.7662e-01, -7.6094e-01, -3.4918e-01,  5.6799e-01,\n",
            "           5.7055e-01],\n",
            "         [ 7.9980e-01, -2.7832e-01, -6.2475e-01, -5.2270e-02, -2.2265e-01,\n",
            "          -4.3895e-01,  4.8315e-01, -5.1322e-01, -1.8621e-01,  2.2086e-01,\n",
            "          -4.3025e-01, -6.0314e-01, -7.1794e-01, -3.1450e-01,  5.3624e-01,\n",
            "           5.0485e-01],\n",
            "         [ 8.1223e-01, -2.6981e-01, -6.2558e-01, -6.5342e-02, -2.1769e-01,\n",
            "          -4.4731e-01,  4.8464e-01, -5.0981e-01, -1.9438e-01,  2.1445e-01,\n",
            "          -4.3760e-01, -6.0379e-01, -7.3085e-01, -3.1827e-01,  5.4949e-01,\n",
            "           5.1419e-01],\n",
            "         [ 8.4316e-01, -3.1458e-01, -5.8485e-01, -9.4314e-02, -2.5703e-01,\n",
            "          -4.3986e-01,  5.1442e-01, -4.8051e-01, -1.8024e-01,  2.2543e-01,\n",
            "          -4.0173e-01, -6.2967e-01, -7.4185e-01, -3.0193e-01,  5.7171e-01,\n",
            "           4.9158e-01],\n",
            "         [ 7.5478e-01, -2.8527e-01, -6.3722e-01, -6.2124e-03, -2.2190e-01,\n",
            "          -4.1888e-01,  4.6831e-01, -5.3311e-01, -1.6909e-01,  2.3432e-01,\n",
            "          -4.2325e-01, -5.9201e-01, -6.7881e-01, -3.1015e-01,  4.9213e-01,\n",
            "           4.8761e-01],\n",
            "         [ 8.1712e-01, -3.2460e-01, -5.8817e-01, -6.7352e-02, -2.6131e-01,\n",
            "          -4.2568e-01,  5.0822e-01, -4.9012e-01, -1.6719e-01,  2.3567e-01,\n",
            "          -3.9274e-01, -6.2545e-01, -7.1729e-01, -2.9708e-01,  5.4522e-01,\n",
            "           4.7743e-01]],\n",
            "\n",
            "        [[ 4.5030e-01, -3.9649e-01, -6.7988e-01,  3.0873e-01, -2.6726e-01,\n",
            "          -2.5564e-01,  3.9339e-01, -6.4731e-01, -1.9709e-02,  3.5161e-01,\n",
            "          -3.2310e-01, -5.4038e-01, -3.9362e-01, -2.5569e-01,  1.8335e-01,\n",
            "           3.2638e-01],\n",
            "         [ 6.1303e-01, -4.1046e-01, -6.0942e-01,  1.4435e-01, -3.0057e-01,\n",
            "          -3.1142e-01,  4.6247e-01, -5.6310e-01, -6.1155e-02,  3.1890e-01,\n",
            "          -3.1633e-01, -5.9500e-01, -5.2251e-01, -2.5616e-01,  3.3641e-01,\n",
            "           3.6150e-01],\n",
            "         [ 5.2086e-01, -5.0989e-01, -5.7964e-01,  2.4323e-01, -3.6586e-01,\n",
            "          -2.3382e-01,  4.6579e-01, -5.7690e-01,  1.8453e-02,  3.8126e-01,\n",
            "          -2.3201e-01, -6.0358e-01, -4.1510e-01, -2.1402e-01,  2.3222e-01,\n",
            "           2.6695e-01],\n",
            "         [ 7.9652e-01, -2.2168e-01, -6.6276e-01, -5.1985e-02, -1.7779e-01,\n",
            "          -4.6197e-01,  4.5947e-01, -5.3271e-01, -2.1484e-01,  1.9850e-01,\n",
            "          -4.7667e-01, -5.8129e-01, -7.3340e-01, -3.3647e-01,  5.4234e-01,\n",
            "           5.4333e-01],\n",
            "         [ 7.4355e-01, -3.5134e-01, -5.9856e-01,  8.7389e-03, -2.7216e-01,\n",
            "          -3.8630e-01,  4.9006e-01, -5.1775e-01, -1.3117e-01,  2.6395e-01,\n",
            "          -3.6866e-01, -6.1292e-01, -6.4843e-01, -2.8397e-01,  4.7064e-01,\n",
            "           4.3857e-01],\n",
            "         [ 8.0240e-01, -1.3602e-01, -7.1616e-01, -6.2561e-02, -1.1144e-01,\n",
            "          -5.0092e-01,  4.2789e-01, -5.5688e-01, -2.6140e-01,  1.6213e-01,\n",
            "          -5.4720e-01, -5.5155e-01, -7.6569e-01, -3.7010e-01,  5.6192e-01,\n",
            "           6.0453e-01],\n",
            "         [ 7.3839e-01, -1.0471e-01, -7.6064e-01,  7.0269e-04, -7.8095e-02,\n",
            "          -4.9005e-01,  3.9050e-01, -5.9816e-01, -2.5860e-01,  1.6445e-01,\n",
            "          -5.7107e-01, -5.2056e-01, -7.2327e-01, -3.7998e-01,  5.0593e-01,\n",
            "           6.0867e-01],\n",
            "         [ 6.9168e-01, -2.3470e-01, -6.9386e-01,  5.5094e-02, -1.7359e-01,\n",
            "          -4.1661e-01,  4.2367e-01, -5.8002e-01, -1.7663e-01,  2.2856e-01,\n",
            "          -4.6296e-01, -5.5421e-01, -6.4331e-01, -3.2758e-01,  4.4015e-01,\n",
            "           5.0540e-01]]], grad_fn=<UnsafeViewBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Multi_Head_Attention():\n",
        "  def __init__(self, head_num=4):\n",
        "    self.head_num = head_num\n",
        "    self.multi_head = nn.ModuleList([Attention_Head() for i in range(head_num)])\n",
        "\n",
        "\n",
        "mha = Multi_Head_Attention()\n",
        "print(mha.multi_head)"
      ],
      "metadata": {
        "id": "LvEwTEBjRoTV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d784673-1a59-4887-9c34-7d8247739449"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ModuleList(\n",
            "  (0-3): 4 x Attention_Head(\n",
            "    (Embed): Embedding(64, 32)\n",
            "    (value_layer): Linear(in_features=2, out_features=16, bias=True)\n",
            "    (key_layer): Linear(in_features=2, out_features=16, bias=True)\n",
            "    (query_layer): Linear(in_features=2, out_features=16, bias=True)\n",
            "    (ln1): Linear(in_features=64, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KmSG0Rummost"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}